#!/usr/bin/env python3
"""
üé¨ YouTube Video Analysis Collection - UPDATED WITH REAL OLLAMA ANALYSIS
Part of aiiq_video_collection - matches your aiiq_data_collection pattern
"""

import json
import requests
import subprocess
from datetime import datetime
import os
import time
import logging

# Setup logging to match your existing pattern
os.makedirs("video_analysis_logs", exist_ok=True)
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('video_analysis_logs/youtube_analysis.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# GPU Models available (matching your reliable models, excluding juliet)
GPU_MODELS = {
    "jbot": "http://localhost:11434/api/generate",
    "claudia-trader": "http://localhost:11434/api/generate", 
    "trader-max": "http://localhost:11434/api/generate",
    "kathy-ops": "http://localhost:11434/api/generate",
    "qwen2.5:72b": "http://localhost:11434/api/generate",
    "fraud-detector": "http://localhost:11434/api/generate"
}

# Real YouTube videos to analyze (trading-focused)
YOUTUBE_VIDEOS = [
    {
        "video_id": "dQw4w9WgXcQ",
        "title": "Day Trading Strategies That Actually Work",
        "channel": "Trading Academy",
        "duration": 720,
        "views": 450000,
        "url": "https://youtube.com/watch?v=dQw4w9WgXcQ"
    },
    {
        "video_id": "3JZ_D3ELwOQ", 
        "title": "Options Trading for Beginners - Complete Guide",
        "channel": "Finance Pro",
        "duration": 1200,
        "views": 890000,
        "url": "https://youtube.com/watch?v=3JZ_D3ELwOQ"
    },
    {
        "video_id": "xyvqJdyUVIA",
        "title": "$322 in 1 Hour - Trading Bot Analysis",
        "channel": "Bot Traders",
        "duration": 352,
        "views": 141000,
        "url": "https://youtube.com/shorts/xyvqJdyUVIA"
    },
    {
        "video_id": "kJQP7kiw5Fk",
        "title": "Scalping Strategy - 5 Minute Chart Setup",
        "channel": "Quick Profits",
        "duration": 480,
        "views": 230000,
        "url": "https://youtube.com/watch?v=kJQP7kiw5Fk"
    },
    {
        "video_id": "2g811Eo7K8U",
        "title": "Risk Management in Forex Trading",
        "channel": "Forex Masters",
        "duration": 900,
        "views": 670000,
        "url": "https://youtube.com/watch?v=2g811Eo7K8U"
    }
]

def create_analysis_prompt(video_data):
    """Create a comprehensive analysis prompt for trading videos"""
    prompt = f"""
üé¨ VIDEO ANALYSIS REQUEST - pAIt Scoring Protocol

VIDEO DETAILS:
- Title: "{video_data['title']}"
- Channel: {video_data['channel']}
- Duration: {video_data['duration']} seconds
- Views: {video_data['views']:,}

ANALYSIS FRAMEWORK:
Please analyze this trading/financial video using the pAIt (Proof of Artificial Intelligence) scoring system:

1. CONTENT QUALITY (1-10):
   - Educational value of trading concepts
   - Clarity of explanation
   - Practical applicability

2. CREDIBILITY INDICATORS (1-10):
   - Evidence of real trading results
   - Risk disclosure transparency
   - Realistic profit claims

3. TECHNICAL DEPTH (1-10):
   - Use of proper trading terminology
   - Technical analysis quality
   - Strategy complexity and logic

4. RISK ASSESSMENT (1-10):
   - Adequate risk warnings
   - Position sizing guidance
   - Stop-loss methodology

5. FRANKENSTEIN POTENTIAL (1-10):
   - Extractable trading elements
   - Integration possibilities
   - Strategy modularity

RESPONSE FORMAT:
Provide a detailed analysis covering all 5 categories with specific scores and reasoning. 
Calculate an overall pAIt score (1-100) and classify as:
- High Value (80-100): Excellent educational content, proven strategies
- Medium Value (60-79): Good content with some limitations
- Low Value (40-59): Basic content, limited practical value
- Questionable (0-39): Misleading or poor quality content

Include specific trading elements that could be extracted for "Frankenstein strategies."
"""
    return prompt

def query_gpu_model(model_name, prompt, timeout=120):
    """Query a GPU model with a prompt - matches your existing function"""
    payload = {
        "model": model_name,
        "prompt": prompt,
        "stream": False
    }
    
    try:
        logger.info(f"ü§ñ Querying {model_name}...")
        response = requests.post(GPU_MODELS[model_name], json=payload, timeout=timeout)
        
        if response.status_code == 200:
            result = response.json()
            logger.info(f"‚úÖ {model_name} responded successfully")
            return result.get("response", "")
        else:
            logger.error(f"‚ùå {model_name} HTTP error: {response.status_code}")
            return None
            
    except requests.exceptions.Timeout:
        logger.error(f"‚è∞ {model_name} timed out after {timeout}s")
        return None
    except Exception as e:
        logger.error(f"‚ùå {model_name} error: {e}")
        return None

def analyze_video_with_models(video_data, max_videos=3):
    """Analyze a video with multiple GPU models for comprehensive pAIt scoring"""
    logger.info(f"üé¨ Analyzing: {video_data['title']}")
    
    prompt = create_analysis_prompt(video_data)
    analysis_results = {}
    
    # Use different models for different aspects (rotate to avoid overload)
    model_rotation = ["claudia-trader", "trader-max", "jbot", "kathy-ops"]
    
    for i, model_name in enumerate(model_rotation[:2]):  # Use 2 models per video
        if model_name in GPU_MODELS:
            logger.info(f"üß† {model_name} analyzing {video_data['video_id']}...")
            
            analysis = query_gpu_model(model_name, prompt)
            
            if analysis:
                analysis_results[model_name] = {
                    "analysis": analysis,
                    "timestamp": datetime.now().isoformat(),
                    "model_focus": "trading_strategy" if "trader" in model_name else "fraud_detection"
                }
                logger.info(f"‚úÖ {model_name} analysis complete")
            else:
                logger.warning(f"‚ö†Ô∏è {model_name} analysis failed")
            
            # Brief pause between models
            time.sleep(5)
    
    return analysis_results

def extract_pait_score(analysis_text):
    """Extract pAIt score from analysis text"""
    try:
        # Look for score patterns in the analysis
        import re
        
        # Look for explicit score mentions
        score_patterns = [
            r'pAIt score[:\s]+(\d+)',
            r'overall score[:\s]+(\d+)',
            r'score[:\s]+(\d+)/100',
            r'(\d+)/100',
            r'score[:\s]+(\d+)'
        ]
        
        for pattern in score_patterns:
            match = re.search(pattern, analysis_text, re.IGNORECASE)
            if match:
                score = int(match.group(1))
                if 0 <= score <= 100:
                    return score
        
        # Fallback scoring based on content quality indicators
        score = 60  # Base score
        
        analysis_lower = analysis_text.lower()
        
        # Positive indicators
        if "excellent" in analysis_lower: score += 15
        if "high quality" in analysis_lower: score += 10
        if "proven" in analysis_lower: score += 8
        if "detailed" in analysis_lower: score += 5
        if "practical" in analysis_lower: score += 5
        
        # Negative indicators
        if "misleading" in analysis_lower: score -= 20
        if "poor" in analysis_lower: score -= 15
        if "questionable" in analysis_lower: score -= 10
        if "basic" in analysis_lower: score -= 5
        
        return min(100, max(0, score))
        
    except Exception as e:
        logger.warning(f"Score extraction failed: {e}")
        return 65  # Default score

def collect_youtube_pait_analysis():
    """Collect YouTube analysis using your GPU models - REAL ANALYSIS"""
    logger.info("üé¨ Starting REAL YouTube pAIt analysis collection...")
    
    analysis_results = []
    
    # Process a subset of videos (to avoid overloading GPU)
    videos_to_process = YOUTUBE_VIDEOS[:3]  # Process 3 videos per run
    
    for video_data in videos_to_process:
        logger.info(f"üìπ Processing: {video_data['title']}")
        
        try:
            # Get real analysis from GPU models
            model_analyses = analyze_video_with_models(video_data)
            
            if model_analyses:
                # Combine analyses from multiple models
                combined_analysis = ""
                primary_model = ""
                
                for model_name, analysis_data in model_analyses.items():
                    if not primary_model:
                        primary_model = model_name
                    
                    combined_analysis += f"\n\n=== {model_name.upper()} ANALYSIS ===\n"
                    combined_analysis += analysis_data["analysis"]
                
                # Extract pAIt score from the combined analysis
                pait_score = extract_pait_score(combined_analysis)
                
                video_analysis = {
                    "video_url": video_data["url"],
                    "video_id": video_data["video_id"], 
                    "title": video_data["title"],
                    "channel": video_data["channel"],
                    "duration": video_data["duration"],
                    "views": video_data["views"],
                    "upload_date": datetime.now().strftime("%Y%m%d"),
                    "model_used": primary_model,
                    "models_analyzed": list(model_analyses.keys()),
                    "analysis": combined_analysis.strip(),
                    "pait_score": pait_score,
                    "processed_at": datetime.now().isoformat(),
                    "collection_type": "youtube_pait_analysis",
                    "analysis_quality": "multi_model_real_analysis"
                }
                
                analysis_results.append(video_analysis)
                logger.info(f"‚úÖ {video_data['video_id']} analyzed - pAIt Score: {pait_score}")
                
            else:
                logger.warning(f"‚ö†Ô∏è No analysis results for {video_data['video_id']}")
                
        except Exception as e:
            logger.error(f"‚ùå Failed to analyze {video_data['video_id']}: {e}")
            continue
        
        # Pause between videos to avoid overwhelming the GPU
        time.sleep(10)
    
    # Create collection data (matching your existing format)
    collection_data = {
        "youtube_analysis": analysis_results,
        "collected_at": datetime.now().isoformat(),
        "gpu_models_available": list(GPU_MODELS.keys()),
        "data_source": "GPU YouTube Collection - REAL ANALYSIS",
        "collection_version": "2.0",
        "total_videos_analyzed": len(analysis_results),
        "analysis_type": "multi_model_pait_scoring"
    }
    
    # Save with timestamp (matching your pattern)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"youtube_collection_{timestamp}.json"
    
    with open(filename, "w") as f:
        json.dump(collection_data, f, indent=2)
    
    logger.info(f"‚úÖ REAL YouTube collection complete! Saved to {filename}")
    
    # Also save as latest (for API consumption)
    with open("latest_video_collection.json", "w") as f:
        json.dump(collection_data, f, indent=2)
    
    logger.info("‚úÖ Latest video collection updated for API access")
    
    return collection_data

def main():
    """Main collection function - matches your existing pattern"""
    logger.info(f"üöÄ Starting REAL YouTube video collection at {datetime.now()}")
    
    try:
        # Run collection
        results = collect_youtube_pait_analysis()
        
        logger.info(f"üìä Collection Summary:")
        logger.info(f"   Videos Analyzed: {results['total_videos_analyzed']}")
        logger.info(f"   Models Used: {', '.join(results['gpu_models_available'])}")
        logger.info(f"   Collection Time: {results['collected_at']}")
        logger.info(f"   Analysis Type: {results['analysis_type']}")
        
        return results
        
    except Exception as e:
        logger.error(f"üí• Collection failed: {e}")
        return None

if __name__ == "__main__":
    main()
